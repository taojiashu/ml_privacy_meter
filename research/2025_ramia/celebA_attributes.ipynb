{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA Range MIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from dataset_loaders import CelebADatasetLoader\n",
    "\n",
    "# If the dataset has been processed previously, set load_from_disk=True\n",
    "# celeba = CelebADatasetLoader(load_from_disk=True, dataset_path=\"datasets/celeba\")\n",
    "celeba = CelebADatasetLoader(load_from_disk=False, dataset_path=\"datasets/celeba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training size:\", len(celeba.training_set))\n",
    "print(\"Test size:\", len(celeba.test_set))\n",
    "print(\"Population size:\", len(celeba.population_set))\n",
    "print(\"Nonmembers size:\", len(celeba.nonmembers_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_all = celeba.load_all_original_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facial_attribute_cnn import FacialAttributeCNN\n",
    "# Load the model\n",
    "model_0 = FacialAttributeCNN()\n",
    "model_1 = FacialAttributeCNN()\n",
    "model_2 = FacialAttributeCNN()\n",
    "model_3 = FacialAttributeCNN()\n",
    "\n",
    "model_0.load_state_dict(torch.load(\"saved_models/celeba/model_0.pt\"))\n",
    "model_1.load_state_dict(torch.load(\"saved_models/celeba/model_1.pt\"))\n",
    "model_2.load_state_dict(torch.load(\"saved_models/celeba/model_2.pt\"))\n",
    "model_3.load_state_dict(torch.load(\"saved_models/celeba/model_3.pt\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_0 = model_0.eval()\n",
    "model_1 = model_1.eval()\n",
    "model_2 = model_2.eval()\n",
    "model_3 = model_3.eval()\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_0 = model_0.to(device)\n",
    "model_1 = model_1.to(device)\n",
    "model_2 = model_2.to(device)\n",
    "model_3 = model_3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_0 = defaultdict(list)\n",
    "loss_1 = defaultdict(list)\n",
    "loss_2 = defaultdict(list)\n",
    "loss_3 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(celeba_all, batch_size=128, shuffle=False)\n",
    "\n",
    "for data, label in tqdm(dataloader):\n",
    "    data = data.to(device)\n",
    "    id = label[-1]\n",
    "    label = label[0].to(\"cuda\").float()\n",
    "\n",
    "    output_0 = model_0(data)\n",
    "    output_1 = model_1(data)\n",
    "    output_2 = model_2(data)\n",
    "    output_3 = model_3(data)\n",
    "\n",
    "    loss_0 = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(output_0, label)\n",
    "    loss_1 = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(output_1, label)\n",
    "    loss_2 = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(output_2, label)\n",
    "    loss_3 = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(output_3, label)\n",
    "\n",
    "    for i in range(len(id)):\n",
    "        loss_0[id[i].item()].append(loss_0[i].detach().cpu().numpy())\n",
    "        loss_1[id[i].item()].append(loss_1[i].detach().cpu().numpy())\n",
    "        loss_2[id[i].item()].append(loss_2[i].detach().cpu().numpy())\n",
    "        loss_3[id[i].item()].append(loss_3[i].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(loss_0, \"results/celeba/model_0_losses.pt\")\n",
    "torch.save(loss_1, \"results/celeba/model_1_losses.pt\")\n",
    "torch.save(loss_2, \"results/celeba/model_2_losses.pt\")\n",
    "torch.save(loss_3, \"results/celeba/model_3_losses.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_loss_for_each_data(loss_dict):\n",
    "    d = {key: np.array(values).mean(1) for key, values in loss_dict.items() if key > 0 and key <= 10177}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [loss_0, loss_1, loss_2, loss_3]\n",
    "losses = [get_average_loss_for_each_data(loss) for loss in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_matrix = np.zeros((4, 10177))\n",
    "split_matrix[0][:5089] = 1\n",
    "split_matrix[1][5089:] = 1\n",
    "split_matrix[2][list(range(0, 2544)) + list(range(5089,7633))] = 1\n",
    "split_matrix[3][list(range(2544, 5089)) + list(range(7633, 10177))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_id = []\n",
    "for key in losses[0].keys():\n",
    "    if len(losses[0][key]) == 1 and key <= 5089:\n",
    "        # print(key)\n",
    "        zero_id.append(key-1)\n",
    "split_matrix[:, zero_id] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from membership_testers.utils import get_rmia_score_dict_from_loss_dicts\n",
    "\n",
    "rmia_score_dict_offline = get_rmia_score_dict_from_loss_dicts(\n",
    "    losses, split_matrix, offline=True, a=0.33\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_rmia_score(rmia_score_dict):\n",
    "    return [max(values) for key, values in rmia_score_dict.items()]\n",
    "\n",
    "def get_topk_average_rmia_score(rmia_score_dict, k, sample=False, sample_size=20):\n",
    "    if sample:\n",
    "        sampled_dict = sample_within_dict(rmia_score_dict, sample_size)\n",
    "    else:\n",
    "        sampled_dict = rmia_score_dict\n",
    "        \n",
    "    return [\n",
    "        values[(-values).argsort()[:min(k, len(values))]].mean()\n",
    "        for key, values in sampled_dict.items()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_samples(dict):\n",
    "    return {\n",
    "        key: values[len(values) // 2 :]\n",
    "        for key, values in dict.items()\n",
    "        if key > 0 and key <= 10177\n",
    "    }\n",
    "\n",
    "\n",
    "def get_train_samples(dict):\n",
    "    return {\n",
    "        key: values[: len(values) // 2]\n",
    "        for key, values in dict.items()\n",
    "        if key > 0 and key <= 10177\n",
    "    }\n",
    "\n",
    "\n",
    "def get_mix_samples(dict, k=0):\n",
    "    return {\n",
    "        key: np.concatenate(\n",
    "            [values[: int(len(values) // 2 * (k / 100))], values[len(values) // 2 :]]\n",
    "        )\n",
    "        for key, values in dict.items()\n",
    "        if key > 0 and key <= 10177\n",
    "    }\n",
    "\n",
    "\n",
    "def sample_within_dict(dict, sample_size):\n",
    "    sampled_dict = {key: values for key, values in dict.items()}\n",
    "    for key, values in sampled_dict.items():\n",
    "        if len(values) <= sample_size:\n",
    "            continue\n",
    "        else:\n",
    "            sample_id = np.random.choice(len(values), sample_size, replace=False)\n",
    "            sampled_dict[key] = values[sample_id]\n",
    "    return sampled_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_list(dict):\n",
    "    return [values for _, values in dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmia_score_dict_test = get_test_samples(rmia_score_dict_offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_multiple_roc_curves\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(split_matrix[0], get_topk_average_rmia_score(rmia_score_dict_test, k=13))\n",
    "\n",
    "plot_multiple_roc_curves(fpr, tpr, \"CelebA RMIA ROC Curve\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "range_mia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
